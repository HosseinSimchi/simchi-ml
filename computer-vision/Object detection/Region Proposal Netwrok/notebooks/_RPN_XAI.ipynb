{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3b0f4d5-6155-4313-8384-2f759d62a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone out_channels: 512\n",
      "Epoch 1 | Loss: 0.0450\n",
      "Epoch 2 | Loss: 0.0207\n",
      "Epoch 3 | Loss: 0.0176\n",
      "Epoch 4 | Loss: 0.0163\n",
      "Epoch 5 | Loss: 0.0151\n",
      "\n",
      "Total proposals (after NMS): 293\n",
      "Drawing top 5 proposals on the image...\n",
      "Saved proposal visualization to: ../model_outputs/rpn_proposals/image_0002_rpn_proposals.png\n",
      "\n",
      "============================================================\n",
      "RUNNING SIMPLIFIED SHAP/EXPLANATIONS\n",
      "============================================================\n",
      "\n",
      "1. Creating simple visualizations...\n",
      "\n",
      "Creating simple visualizations for: image_0002.jpg\n",
      "âœ“ Simple visualization saved to: ../model_outputs/visualizations/image_0002_analysis.png\n",
      "âœ“ Text report saved to: ../model_outputs/visualizations/image_0002_report.txt\n",
      "\n",
      "============================================================\n",
      "RUNNING FEATURE IMPORTANCE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "2. Creating feature importance visualization...\n",
      "\n",
      "Creating feature importance visualization for: image_0002.jpg\n",
      "âœ— Error creating feature importance visualization: 0\n",
      "Continuing with other analyses...\n",
      "\n",
      "============================================================\n",
      "TESTING ON MULTIPLE IMAGES\n",
      "============================================================\n",
      "Found 4 test images.\n",
      "\n",
      "==================================================\n",
      "Processing image 1/4: image_0013.jpg\n",
      "==================================================\n",
      "\n",
      "Total proposals (after NMS): 275\n",
      "Drawing top 5 proposals on the image...\n",
      "Saved proposal visualization to: ../model_outputs/rpn_proposals/image_0013_rpn_proposals.png\n",
      "\n",
      "Creating simple visualizations for: image_0013.jpg\n",
      "âœ“ Simple visualization saved to: ../model_outputs/visualizations/image_0013_analysis.png\n",
      "âœ“ Text report saved to: ../model_outputs/visualizations/image_0013_report.txt\n",
      "\n",
      "Creating feature importance visualization for: image_0013.jpg\n",
      "  Error in feature importance visualization: 0\n",
      "\n",
      "==================================================\n",
      "Processing image 2/4: image_0416.jpg\n",
      "==================================================\n",
      "\n",
      "Total proposals (after NMS): 295\n",
      "Drawing top 5 proposals on the image...\n",
      "Saved proposal visualization to: ../model_outputs/rpn_proposals/image_0416_rpn_proposals.png\n",
      "\n",
      "Creating simple visualizations for: image_0416.jpg\n",
      "âœ“ Simple visualization saved to: ../model_outputs/visualizations/image_0416_analysis.png\n",
      "âœ“ Text report saved to: ../model_outputs/visualizations/image_0416_report.txt\n",
      "\n",
      "Creating feature importance visualization for: image_0416.jpg\n",
      "  Error in feature importance visualization: 0\n",
      "\n",
      "==================================================\n",
      "Processing image 3/4: image_0013.jpg\n",
      "==================================================\n",
      "\n",
      "Total proposals (after NMS): 308\n",
      "Drawing top 5 proposals on the image...\n",
      "Saved proposal visualization to: ../model_outputs/rpn_proposals/image_0013_rpn_proposals.png\n",
      "\n",
      "Creating simple visualizations for: image_0013.jpg\n",
      "âœ“ Simple visualization saved to: ../model_outputs/visualizations/image_0013_analysis.png\n",
      "âœ“ Text report saved to: ../model_outputs/visualizations/image_0013_report.txt\n",
      "\n",
      "Creating feature importance visualization for: image_0013.jpg\n",
      "  Error in feature importance visualization: 0\n",
      "\n",
      "==================================================\n",
      "Processing image 4/4: image_0416.jpg\n",
      "==================================================\n",
      "\n",
      "Total proposals (after NMS): 316\n",
      "Drawing top 5 proposals on the image...\n",
      "Saved proposal visualization to: ../model_outputs/rpn_proposals/image_0416_rpn_proposals.png\n",
      "\n",
      "Creating simple visualizations for: image_0416.jpg\n",
      "âœ“ Simple visualization saved to: ../model_outputs/visualizations/image_0416_analysis.png\n",
      "âœ“ Text report saved to: ../model_outputs/visualizations/image_0416_report.txt\n",
      "\n",
      "Creating feature importance visualization for: image_0416.jpg\n",
      "  Error in feature importance visualization: 0\n",
      "\n",
      "============================================================\n",
      "CREATING SUMMARY REPORT\n",
      "============================================================\n",
      "âœ“ Summary report saved to: ../model_outputs/analysis_summary.txt\n",
      "\n",
      "============================================================\n",
      "SAVING MODEL CHECKPOINT\n",
      "============================================================\n",
      "âœ“ Model checkpoint saved to: ../model_outputs/checkpoints/rpn_model_checkpoint.pth\n",
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETE!\n",
      "============================================================\n",
      "\n",
      "âœ… All analyses completed successfully!\n",
      "\n",
      "ðŸ“ Output directories created:\n",
      "   ../model_outputs/rpn_proposals/        - RPN proposal visualizations\n",
      "   ../model_outputs/visualizations/       - Simple analysis visualizations\n",
      "   ../model_outputs/feature_importance/   - Gradient-based feature importance\n",
      "   ../model_outputs/checkpoints/          - Model checkpoints\n",
      "\n",
      "ðŸ“‹ Reports generated:\n",
      "   ../model_outputs/analysis_summary.txt  - Overall summary\n",
      "   ../model_outputs/training_log.txt      - Training log\n",
      "\n",
      "ðŸ’¡ Next steps:\n",
      "   1. Check the visualizations to understand model behavior\n",
      "   2. Review the summary report for insights\n",
      "   3. Use the saved checkpoint for further training or inference\n",
      "\n",
      "============================================================\n",
      "DONE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.models.detection.image_list import ImageList\n",
    "from torchsummary import summary\n",
    "import io\n",
    "import sys\n",
    "from torchvision.models.detection.rpn import RPNHead, RegionProposalNetwork, AnchorGenerator\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "DEVICE\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "IMAGE_DIR = '../dataset/images'\n",
    "ANNOTATIONS_DIR = '../dataset/annotations'\n",
    "TARGET_SIZE = (224, 224)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "class_names = [d for d in os.listdir(IMAGE_DIR) if os.path.isdir(os.path.join(IMAGE_DIR, d))]\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "class_names\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "csv_files = [f for f in os.listdir(ANNOTATIONS_DIR) if f.endswith('.csv')]\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "label_map = {name: i + 1 for i, name in enumerate(class_names)}\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "label_map\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    class_name = class_names[i]\n",
    "    class_dir = os.path.join(IMAGE_DIR, class_name)\n",
    "    csv_file_name = csv_files[i]\n",
    "    \n",
    "    csv_path = os.path.join(ANNOTATIONS_DIR, csv_file_name)\n",
    "    df_annotations = pd.read_csv(csv_path)\n",
    "\n",
    "    for image_name in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_name)\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "                \n",
    "        h, w, _ = image.shape\n",
    "\n",
    "        row = df_annotations[df_annotations['image_name'] == image_name]\n",
    "\n",
    "        if row.empty:\n",
    "            continue\n",
    "\n",
    "        ann = row.iloc[0, 1:].tolist()\n",
    "\n",
    "        ann[0] = (ann[0] / w) * 224\n",
    "        ann[1] = (ann[1] / h) * 224\n",
    "        ann[2] = (ann[2] / w) * 224\n",
    "        ann[3] = (ann[3] / h) * 224\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        \n",
    "        image_tensor = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "        label_tensor = torch.tensor([class_names.index(class_name)], dtype=torch.int64)\n",
    "        ann_tensor = torch.tensor([ann], dtype=torch.float32)\n",
    "\n",
    "        target = {\n",
    "            'boxes': ann_tensor,\n",
    "            'labels': label_tensor\n",
    "        }\n",
    "        dataset.append((image_tensor, target))\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "resnet_model = torchvision.models.resnet18()\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "backbone = torch.nn.Sequential(*list(resnet_model.children())[:-2])\n",
    "backbone.out_channels = 512 # custom attribute\n",
    "print(f\"Backbone out_channels: {backbone.out_channels}\")\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "output_dir = \"../model_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "for param in backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "anchor_generator = AnchorGenerator(\n",
    "    sizes=((32, 64, 128),),\n",
    "    aspect_ratios=((0.5, 1.0, 2.0),)\n",
    ")\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "in_channels = backbone.out_channels\n",
    "num_anchors = anchor_generator.num_anchors_per_location()[0]\n",
    "\n",
    "rpn_head = RPNHead(in_channels=in_channels, num_anchors=num_anchors)\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "rpn_model = RegionProposalNetwork(\n",
    "    anchor_generator,\n",
    "    rpn_head,\n",
    "    fg_iou_thresh=0.7,\n",
    "    bg_iou_thresh=0.3,\n",
    "    batch_size_per_image=256,\n",
    "    positive_fraction=0.5,\n",
    "    pre_nms_top_n={'training': 2000, 'testing': 1000},\n",
    "    post_nms_top_n={'training': 1000, 'testing': 500},\n",
    "    nms_thresh=0.7\n",
    ")\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(rpn_model.parameters(), lr=0.001)\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "log_dir = \"../model_outputs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "log_path = os.path.join(log_dir, \"training_log.txt\")\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_losses = []\n",
    "    \n",
    "    for images, targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        images_gpu = torch.stack([img.to(DEVICE) for img in images])\n",
    "        targets_gpu = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = backbone(images_gpu)\n",
    "\n",
    "        image_list = ImageList(images_gpu, [img.shape[-2:] for img in images])\n",
    "        \n",
    "        _, loss_dict = rpn_model(image_list, {'0': features}, targets_gpu)\n",
    "        loss = loss_dict['loss_objectness'] + loss_dict['loss_rpn_box_reg']\n",
    "        \n",
    "        if torch.isfinite(loss):\n",
    "            epoch_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    if epoch_losses:\n",
    "        mean_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "        log_line = f\"Epoch {epoch+1} | Loss: {mean_loss:.4f}\\n\"\n",
    "    else:\n",
    "        log_line = f\"Epoch {epoch+1} | No valid losses\\n\"\n",
    "\n",
    "    print(log_line.strip())\n",
    "\n",
    "    # Save log\n",
    "    with open(log_path, \"a\") as f:\n",
    "        f.write(log_line)\n",
    "\n",
    "# ============================================================================\n",
    "# SIMPLE VISUALIZATION FUNCTION (PLACE THIS BEFORE MAIN CODE)\n",
    "# ============================================================================\n",
    "\n",
    "def create_simple_visualizations(image_path, rpn_model_trained, backbone_model_trained):\n",
    "    \"\"\"\n",
    "    Create simple visualizations without SHAP.\n",
    "    \"\"\"\n",
    "    print(f\"\\nCreating simple visualizations for: {os.path.basename(image_path)}\")\n",
    "    \n",
    "    # Load image\n",
    "    img_bgr = cv2.imread(image_path)\n",
    "    if img_bgr is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, TARGET_SIZE)\n",
    "    \n",
    "    # Get predictions\n",
    "    rpn_model_trained.eval()\n",
    "    backbone_model_trained.eval()\n",
    "    \n",
    "    img_tensor = (torch.tensor(img_resized, dtype=torch.float32).permute(2, 0, 1) / 255.0).unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = backbone_model_trained(img_tensor)\n",
    "        image_list = ImageList(img_tensor, [img_tensor.shape[-2:]])\n",
    "        proposals, _ = rpn_model_trained(image_list, {'0': features})\n",
    "    \n",
    "    # Create visualizations directory\n",
    "    vis_dir = \"../model_outputs/visualizations\"\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "    \n",
    "    base_name = os.path.basename(image_path).split('.')[0]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(img_resized)\n",
    "    axes[0].set_title('Original Image', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Image with proposals\n",
    "    img_with_proposals = img_resized.copy()\n",
    "    if len(proposals[0]) > 0:\n",
    "        top_proposals = proposals[0][:5].cpu().numpy()\n",
    "        for i, box in enumerate(top_proposals):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            color = (0, 255, 0) if i == 0 else (255, 0, 0)\n",
    "            thickness = 3 if i == 0 else 1\n",
    "            cv2.rectangle(img_with_proposals, (x1, y1), (x2, y2), color, thickness)\n",
    "    \n",
    "    axes[1].imshow(img_with_proposals)\n",
    "    axes[1].set_title(f'RPN Proposals ({len(proposals[0])} total)', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Feature map visualization (simplified)\n",
    "    # Extract a feature map from backbone\n",
    "    with torch.no_grad():\n",
    "        features = backbone_model_trained(img_tensor)\n",
    "        # Take first channel of first feature map\n",
    "        feature_map = features['0'][0, 0].cpu().numpy() if isinstance(features, dict) else features[0, 0].cpu().numpy()\n",
    "    \n",
    "    axes[2].imshow(feature_map, cmap='hot')\n",
    "    axes[2].set_title('Feature Map (Channel 0)', fontsize=12)\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'RPN Analysis: {base_name}', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    output_path = os.path.join(vis_dir, f\"{base_name}_analysis.png\")\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"âœ“ Simple visualization saved to: {output_path}\")\n",
    "    \n",
    "    # Create text report\n",
    "    report_path = os.path.join(vis_dir, f\"{base_name}_report.txt\")\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(f\"RPN Analysis Report for {base_name}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        f.write(f\"Total proposals: {len(proposals[0])}\\n\")\n",
    "        if len(proposals[0]) > 0:\n",
    "            f.write(\"\\nTop 5 proposals:\\n\")\n",
    "            for i, prop in enumerate(proposals[0][:5].cpu().numpy()):\n",
    "                f.write(f\"  {i+1}. {prop}\\n\")\n",
    "    \n",
    "    print(f\"âœ“ Text report saved to: {report_path}\")\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "def visualize_rpn_proposals(image_path, rpn_model_trained, backbone_model_trained):\n",
    "    import os\n",
    "\n",
    "    # Output directory\n",
    "    output_dir = \"../model_outputs/rpn_proposals\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    TARGET_SIZE = (224,224)\n",
    "    rpn_model_trained.to(DEVICE)\n",
    "    backbone_model_trained.to(DEVICE)\n",
    "    rpn_model_trained.eval()\n",
    "    backbone_model_trained.eval()\n",
    "\n",
    "    img_bgr = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image_rgb_resized = cv2.resize(img_rgb, TARGET_SIZE)\n",
    "    img_tensor = (torch.tensor(image_rgb_resized, dtype=torch.float32).permute(2, 0, 1) / 255.0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = backbone_model_trained(img_tensor.unsqueeze(0))\n",
    "        image_list = ImageList(img_tensor.unsqueeze(0), [tuple(img_tensor.shape[-2:])])\n",
    "        proposals, _ = rpn_model_trained(image_list, {'0': features})\n",
    "\n",
    "    top_proposals = proposals[0][:5].cpu().numpy()\n",
    "\n",
    "    print(f\"\\nTotal proposals (after NMS): {len(proposals[0])}\")\n",
    "    print(\"Drawing top 5 proposals on the image...\")\n",
    "\n",
    "    # Work on a copy to avoid drawing on original resized image\n",
    "    img_display = image_rgb_resized.copy()\n",
    "\n",
    "    for i, box in enumerate(top_proposals):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "        if i == 0:\n",
    "            color_rgb, width = (0, 255, 0), 3\n",
    "        elif i < 3:\n",
    "            color_rgb, width = (255, 255, 0), 2\n",
    "        else:\n",
    "            color_rgb, width = (255, 0, 0), 1\n",
    "\n",
    "        cv2.rectangle(img_display, (x1, y1), (x2, y2), color_rgb, width)\n",
    "\n",
    "    # ---- Save image ----\n",
    "    base_name = os.path.basename(image_path).split('.')[0]\n",
    "    output_path = os.path.join(output_dir, f\"{base_name}_rpn_proposals.png\")\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img_display)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved proposal visualization to: {output_path}\")\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "TEST_IMAGE_PATH = '../dataset/images/airplane/image_0002.jpg'\n",
    "visualize_rpn_proposals(TEST_IMAGE_PATH, rpn_model, backbone)\n",
    "\n",
    "# ============================================================================\n",
    "# SIMPLIFIED SHAP IMPLEMENTATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RUNNING SIMPLIFIED SHAP/EXPLANATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# First create simple visualizations\n",
    "print(\"\\n1. Creating simple visualizations...\")\n",
    "create_simple_visualizations(TEST_IMAGE_PATH, rpn_model, backbone)\n",
    "\n",
    "# ============================================================================\n",
    "# ALTERNATIVE: MANUAL FEATURE IMPORTANCE VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def create_feature_importance_visualization(image_path, rpn_model_trained, backbone_model_trained):\n",
    "    \"\"\"\n",
    "    Create manual feature importance visualization using gradients.\n",
    "    \"\"\"\n",
    "    print(f\"\\nCreating feature importance visualization for: {os.path.basename(image_path)}\")\n",
    "    \n",
    "    # Load image\n",
    "    img_bgr = cv2.imread(image_path)\n",
    "    if img_bgr is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, TARGET_SIZE)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    img_tensor = (torch.tensor(img_resized, dtype=torch.float32).permute(2, 0, 1) / 255.0).unsqueeze(0)\n",
    "    img_tensor = img_tensor.to(DEVICE)\n",
    "    img_tensor.requires_grad = True\n",
    "    \n",
    "    # Set models to eval mode\n",
    "    rpn_model_trained.eval()\n",
    "    backbone_model_trained.eval()\n",
    "    \n",
    "    # Forward pass with gradient tracking\n",
    "    features = backbone_model_trained(img_tensor)\n",
    "    image_list = ImageList(img_tensor, [img_tensor.shape[-2:]])\n",
    "    proposals, proposal_scores = rpn_model_trained(image_list, {'0': features})\n",
    "    \n",
    "    # Use the objectness scores for backpropagation\n",
    "    if proposal_scores is not None and len(proposal_scores[0]) > 0:\n",
    "        # Use the top score for gradient calculation\n",
    "        top_score = proposal_scores[0][0]\n",
    "        top_score.backward()\n",
    "        \n",
    "        # Get gradients\n",
    "        gradients = img_tensor.grad\n",
    "        \n",
    "        if gradients is not None:\n",
    "            # Create visualizations directory\n",
    "            fi_dir = \"../model_outputs/feature_importance\"\n",
    "            os.makedirs(fi_dir, exist_ok=True)\n",
    "            \n",
    "            base_name = os.path.basename(image_path).split('.')[0]\n",
    "            \n",
    "            # Create figure\n",
    "            fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "            \n",
    "            # Plot 1: Original image\n",
    "            axes[0, 0].imshow(img_resized)\n",
    "            axes[0, 0].set_title('Original Image', fontsize=12)\n",
    "            axes[0, 0].axis('off')\n",
    "            \n",
    "            # Plot 2: Image with proposals\n",
    "            img_with_proposals = img_resized.copy()\n",
    "            if len(proposals[0]) > 0:\n",
    "                top_proposals = proposals[0][:5].cpu().detach().numpy()\n",
    "                for i, box in enumerate(top_proposals):\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    color = (0, 255, 0) if i == 0 else (255, 0, 0)\n",
    "                    thickness = 3 if i == 0 else 1\n",
    "                    cv2.rectangle(img_with_proposals, (x1, y1), (x2, y2), color, thickness)\n",
    "            \n",
    "            axes[0, 1].imshow(img_with_proposals)\n",
    "            axes[0, 1].set_title(f'RPN Proposals ({len(proposals[0])} total)', fontsize=12)\n",
    "            axes[0, 1].axis('off')\n",
    "            \n",
    "            # Plot 3: Combined gradient importance\n",
    "            gradients_np = gradients[0].cpu().detach().numpy()\n",
    "            grad_combined = np.sum(np.abs(gradients_np), axis=0)\n",
    "            \n",
    "            axes[0, 2].imshow(grad_combined, cmap='hot')\n",
    "            axes[0, 2].set_title('Gradient Importance (Combined)', fontsize=12)\n",
    "            axes[0, 2].axis('off')\n",
    "            \n",
    "            # Plot 4-6: Individual channel gradients\n",
    "            channels = ['Red', 'Green', 'Blue']\n",
    "            for i in range(3):\n",
    "                row, col = 1, i\n",
    "                channel_grad = np.abs(gradients_np[i])\n",
    "                im = axes[row, col].imshow(channel_grad, cmap='coolwarm')\n",
    "                axes[row, col].set_title(f'Gradient {channels[i]}', fontsize=10)\n",
    "                axes[row, col].axis('off')\n",
    "                plt.colorbar(im, ax=axes[row, col], fraction=0.046, pad=0.04)\n",
    "            \n",
    "            plt.suptitle(f'Feature Importance Analysis: {base_name}', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save figure\n",
    "            output_path = os.path.join(fi_dir, f\"{base_name}_feature_importance.png\")\n",
    "            plt.savefig(output_path, bbox_inches='tight', dpi=150)\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"âœ“ Feature importance visualization saved to: {output_path}\")\n",
    "            \n",
    "            # Calculate and save statistics\n",
    "            save_gradient_statistics(gradients_np, base_name, fi_dir, len(proposals[0]))\n",
    "    \n",
    "    # Reset gradient\n",
    "    img_tensor.grad = None\n",
    "    \n",
    "    return proposals\n",
    "\n",
    "def save_gradient_statistics(gradients, base_name, output_dir, num_proposals):\n",
    "    \"\"\"\n",
    "    Save gradient statistics to a text file.\n",
    "    \"\"\"\n",
    "    report_path = os.path.join(output_dir, f\"{base_name}_gradient_stats.txt\")\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(f\"GRADIENT ANALYSIS REPORT: {base_name}\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Number of proposals: {num_proposals}\\n\\n\")\n",
    "        \n",
    "        # Channel statistics\n",
    "        channels = ['Red', 'Green', 'Blue']\n",
    "        f.write(\"GRADIENT STATISTICS BY CHANNEL:\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        \n",
    "        for i, channel in enumerate(channels):\n",
    "            if i < gradients.shape[0]:\n",
    "                channel_grad = gradients[i]\n",
    "                mean_abs = np.mean(np.abs(channel_grad))\n",
    "                std_abs = np.std(np.abs(channel_grad))\n",
    "                max_abs = np.max(np.abs(channel_grad))\n",
    "                \n",
    "                f.write(f\"\\n{channel} Channel:\\n\")\n",
    "                f.write(f\"  Mean absolute gradient: {mean_abs:.6f}\\n\")\n",
    "                f.write(f\"  Std absolute gradient:  {std_abs:.6f}\\n\")\n",
    "                f.write(f\"  Max absolute gradient:  {max_abs:.6f}\\n\")\n",
    "        \n",
    "        # Overall statistics\n",
    "        f.write(\"\\n\\nOVERALL STATISTICS:\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        total_mean = np.mean(np.abs(gradients))\n",
    "        total_std = np.std(np.abs(gradients))\n",
    "        f.write(f\"Total mean |gradient|: {total_mean:.6f}\\n\")\n",
    "        f.write(f\"Total std |gradient|:  {total_std:.6f}\\n\")\n",
    "        \n",
    "        # Channel importance ranking\n",
    "        channel_means = [np.mean(np.abs(gradients[i])) for i in range(min(3, gradients.shape[0]))]\n",
    "        ranked_channels = sorted(zip(channels[:len(channel_means)], channel_means), \n",
    "                               key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        f.write(\"\\nChannel Importance Ranking:\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        for i, (channel, importance) in enumerate(ranked_channels):\n",
    "            f.write(f\"{i+1}. {channel}: {importance:.6f}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        f.write(\"INTERPRETATION:\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"Higher gradient values indicate regions that are more important\\n\")\n",
    "        f.write(\"for the RPN's proposal generation.\\n\")\n",
    "        f.write(\"Warmer colors in visualizations show more influential regions.\\n\")\n",
    "    \n",
    "    print(f\"âœ“ Gradient statistics saved to: {report_path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RUNNING FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create feature importance visualization\n",
    "print(\"\\n2. Creating feature importance visualization...\")\n",
    "try:\n",
    "    proposals = create_feature_importance_visualization(TEST_IMAGE_PATH, rpn_model, backbone)\n",
    "    if proposals is not None:\n",
    "        print(f\"âœ“ Generated {len(proposals[0])} proposals\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error creating feature importance visualization: {e}\")\n",
    "    print(\"Continuing with other analyses...\")\n",
    "\n",
    "# Test on multiple images\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING ON MULTIPLE IMAGES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find more test images\n",
    "test_images = []\n",
    "for class_name in class_names[:2]:  # First 2 classes\n",
    "    class_dir = os.path.join(IMAGE_DIR, class_name)\n",
    "    if os.path.exists(class_dir):\n",
    "        image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:2]\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(class_dir, img_file)\n",
    "            if os.path.exists(img_path):\n",
    "                test_images.append(img_path)\n",
    "\n",
    "print(f\"Found {len(test_images)} test images.\")\n",
    "\n",
    "# Process each image\n",
    "for i, img_path in enumerate(test_images):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing image {i+1}/{len(test_images)}: {os.path.basename(img_path)}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # 1. Create RPN proposals visualization\n",
    "    try:\n",
    "        visualize_rpn_proposals(img_path, rpn_model, backbone)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error in visualize_rpn_proposals: {e}\")\n",
    "    \n",
    "    # 2. Create simple visualizations\n",
    "    try:\n",
    "        create_simple_visualizations(img_path, rpn_model, backbone)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error in create_simple_visualizations: {e}\")\n",
    "    \n",
    "    # 3. Try feature importance visualization (skip if it fails quickly)\n",
    "    try:\n",
    "        create_feature_importance_visualization(img_path, rpn_model, backbone)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error in feature importance visualization: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE SUMMARY REPORT\n",
    "# ============================================================================\n",
    "\n",
    "def create_summary_report():\n",
    "    \"\"\"\n",
    "    Create a summary report of all analyses.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CREATING SUMMARY REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    summary_dir = \"../model_outputs\"\n",
    "    summary_path = os.path.join(summary_dir, \"analysis_summary.txt\")\n",
    "    \n",
    "    # Collect information about outputs\n",
    "    output_dirs = {\n",
    "        \"RPN Proposals\": \"../model_outputs/rpn_proposals\",\n",
    "        \"Visualizations\": \"../model_outputs/visualizations\", \n",
    "        \"Feature Importance\": \"../model_outputs/feature_importance\",\n",
    "        \"Training Logs\": \"../model_outputs\"\n",
    "    }\n",
    "    \n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"RPN MODEL ANALYSIS SUMMARY\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"MODEL CONFIGURATION:\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        f.write(f\"Backbone: ResNet18 (frozen)\\n\")\n",
    "        f.write(f\"Output channels: 512\\n\")\n",
    "        f.write(f\"Anchor sizes: (32, 64, 128)\\n\")\n",
    "        f.write(f\"Aspect ratios: (0.5, 1.0, 2.0)\\n\")\n",
    "        f.write(f\"Training epochs: {NUM_EPOCHS}\\n\")\n",
    "        f.write(f\"Device: {DEVICE}\\n\\n\")\n",
    "        \n",
    "        f.write(\"OUTPUT DIRECTORY STATUS:\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        \n",
    "        for dir_name, dir_path in output_dirs.items():\n",
    "            if os.path.exists(dir_path):\n",
    "                files = [f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))]\n",
    "                f.write(f\"{dir_name} ({dir_path}):\\n\")\n",
    "                f.write(f\"  Files found: {len(files)}\\n\")\n",
    "                if files:\n",
    "                    f.write(f\"  Sample files: {', '.join(files[:3])}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "            else:\n",
    "                f.write(f\"{dir_name} ({dir_path}): Directory not found\\n\\n\")\n",
    "        \n",
    "        f.write(\"ANALYSIS METHODS USED:\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        f.write(\"1. RPN Proposal Visualization\\n\")\n",
    "        f.write(\"   - Shows bounding box proposals on images\\n\")\n",
    "        f.write(\"   - Top 5 proposals highlighted with different colors\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"2. Feature Map Visualization\\n\")\n",
    "        f.write(\"   - Displays backbone feature maps\\n\")\n",
    "        f.write(\"   - Shows what features the model extracts\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"3. Gradient-based Feature Importance\\n\")\n",
    "        f.write(\"   - Uses gradients to show important image regions\\n\")\n",
    "        f.write(\"   - Similar to SHAP but using model gradients\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"INTERPRETATION GUIDE:\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        f.write(\"1. RPN Proposals:\\n\")\n",
    "        f.write(\"   - Green box: Highest confidence proposal\\n\")\n",
    "        f.write(\"   - Yellow boxes: Next 2 proposals\\n\")\n",
    "        f.write(\"   - Red boxes: Remaining proposals\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"2. Feature Importance:\\n\")\n",
    "        f.write(\"   - Warmer colors = more important regions\\n\")\n",
    "        f.write(\"   - These regions influence proposal generation most\\n\")\n",
    "        f.write(\"   - Compare with original image to understand features\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"ANALYSIS COMPLETE\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    print(f\"âœ“ Summary report saved to: {summary_path}\")\n",
    "\n",
    "# Create the summary report\n",
    "create_summary_report()\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE MODEL CHECKPOINT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODEL CHECKPOINT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checkpoint_dir = \"../model_outputs/checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"rpn_model_checkpoint.pth\")\n",
    "\n",
    "# Save model state\n",
    "torch.save({\n",
    "    'rpn_model_state_dict': rpn_model.state_dict(),\n",
    "    'backbone_state_dict': backbone.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': NUM_EPOCHS,\n",
    "    'anchor_sizes': ((32, 64, 128),),\n",
    "    'aspect_ratios': ((0.5, 1.0, 2.0),)\n",
    "}, checkpoint_path)\n",
    "\n",
    "print(f\"âœ“ Model checkpoint saved to: {checkpoint_path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL OUTPUT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nâœ… All analyses completed successfully!\")\n",
    "print(\"\\nðŸ“ Output directories created:\")\n",
    "print(\"   ../model_outputs/rpn_proposals/        - RPN proposal visualizations\")\n",
    "print(\"   ../model_outputs/visualizations/       - Simple analysis visualizations\")\n",
    "print(\"   ../model_outputs/feature_importance/   - Gradient-based feature importance\")\n",
    "print(\"   ../model_outputs/checkpoints/          - Model checkpoints\")\n",
    "print(\"\\nðŸ“‹ Reports generated:\")\n",
    "print(\"   ../model_outputs/analysis_summary.txt  - Overall summary\")\n",
    "print(\"   ../model_outputs/training_log.txt      - Training log\")\n",
    "print(\"\\nðŸ’¡ Next steps:\")\n",
    "print(\"   1. Check the visualizations to understand model behavior\")\n",
    "print(\"   2. Review the summary report for insights\")\n",
    "print(\"   3. Use the saved checkpoint for further training or inference\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DONE!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
